{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Basic imports\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "\n",
    "# WARNING: These global declarations cause the parallel implementation to \n",
    "# crash when executed on Windows\n",
    "connections = None\n",
    "networks = None\n",
    "flowdepthvel = None\n",
    "\n",
    "from sys import platform\n",
    "if platform == \"linux\" or platform == \"linux2\":\n",
    "    pass\n",
    "elif platform == \"darwin\":\n",
    "    pass\n",
    "elif platform == \"win32\":\n",
    "    print('The parallel version of compute_nhd_routing.py will not execute as currently')\n",
    "    print('written due to the lack of a fork() capability in the windows OS.')\n",
    "    print('For parallel execution, please us a *nix OS.')\n",
    "    print('\\nexiting...')\n",
    "    sys.exit()\n",
    "    # Some useful references:\n",
    "    # https://stackoverflow.com/questions/985281/what-is-the-closest-thing-windows-has-to-fork/985525#985525\n",
    "    # https://stackoverflow.com/questions/8220108/how-do-i-check-the-operating-system-in-python\n",
    "    # https://stackoverflow.com/questions/6596617/python-multiprocess-diff-between-windows-and-linux\n",
    "\n",
    "ENV_IS_CL = False\n",
    "if ENV_IS_CL: root = '/content/wrf_hydro_nwm_public/trunk/NDHMS/dynamic_channel_routing/'\n",
    "elif not ENV_IS_CL: \n",
    "    sys.setrecursionlimit(4000)\n",
    "#     root = os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))\n",
    "    root = os.path.dirname(os.path.dirname(os.path.abspath('')))\n",
    "    sys.path.append(os.path.join(root, r'src', r'python_framework'))\n",
    "    sys.path.append(os.path.join(root, r'src', r'python_routing')) #by Dong Ha\n",
    "    fortran_source_dir = os.path.join(root, r'src', r'fortran_routing', r'mc_pylink_v00', r'MC_singleRCH_singleTS')\n",
    "    sys.path.append(fortran_source_dir)\n",
    "    #from mc_singleCh_SingleTStep import compute_mc_reach_up2down\n",
    "    # import mc_sc_stime as mc\n",
    "    import mc_sseg_stime_noIC as mc\n",
    "\n",
    "## network and reach utilities\n",
    "import nhd_network_utilities as nnu\n",
    "import nhd_reach_utilities as nru\n",
    "import channel_routing_tools as crt\n",
    "\n",
    "## Muskingum Cunge\n",
    "import numpy as np\n",
    "\n",
    "def mc_route_network(\n",
    "          terminal_segment = None\n",
    "        , network = None\n",
    "        , supernetwork_data = None\n",
    "        , nts = None\n",
    "        , dt_mc= None\n",
    "        , latflow= None\n",
    "#         , connections = None\n",
    "        , verbose = False\n",
    "        , debuglevel = 0\n",
    "        ):\n",
    "\n",
    "    global connections\n",
    "    global flowdepthvel \n",
    "\n",
    "    if verbose: print(f\"Executing simulation on network {terminal_segment} beginning with streams of order {network['maximum_reach_seqorder']}\")\n",
    "\n",
    "    ##------------------------------------------------------------------------\n",
    "    ## Compute ordered_reaches and last_segment_reach for all the segments of\n",
    "    ## reach referenced by head_segment\n",
    "    ##------------------------------------------------------------------------\n",
    "    ordered_reaches = {}\n",
    "    # Start: By Dong Ha\n",
    "    last_segment_reach={}\n",
    "    #End    \n",
    "    for head_segment, reach in network['reaches'].items():\n",
    "        if reach['seqorder'] not in ordered_reaches:\n",
    "            ordered_reaches.update({reach['seqorder']:[]}) #TODO: Should this be a set/dictionary?\n",
    "        ordered_reaches[reach['seqorder']].append([head_segment, reach])\n",
    "        # Start: By Dong Ha\n",
    "        seg_list=list(reach['segments_list'])\n",
    "        lastseg=seg_list[0]\n",
    "        last_segment_reach[head_segment]= lastseg\n",
    "        # End \n",
    "\n",
    "    ##-------------------------------------------\n",
    "    ## From jorder= maximum_reach_order to zero\n",
    "    ##     From each reach that has jorder\n",
    "    ##         run mc routing of a chosen scheme\n",
    "    ##\n",
    "    ## Output-> flowdepthvel\n",
    "    ##--------------------------------------------\n",
    "    #Note that not networks but network that takes networks values corresponding to 'terminal_segment' keys.\n",
    "    #Also, network here takes 'terminal_segment' key only at the lower end of a network.      \n",
    "    for x in range(network['maximum_reach_seqorder'],-1,-1):    \n",
    "        \n",
    "        for head_segment, reach in ordered_reaches[x]:       \n",
    "#             print(latflow)\n",
    "            ## START: run MC over each segment over entire timesteps\n",
    "            crt.mc_tlp_over_seg(\n",
    "                            connections= connections \n",
    "                            ,supernetwork_data= supernetwork_data\n",
    "                            ,reach= reach\n",
    "                            ,last_segment_reach= last_segment_reach\n",
    "                            ,nts= nts\n",
    "                            ,dt_mc= dt_mc\n",
    "                            ,latflow= latflow\n",
    "                            ,flowdepthvel= flowdepthvel\n",
    "                            )            \n",
    "            ## END: MC-computed results for flow, vel, and depth are stored in 'flowdepthvel'\n",
    "           \n",
    "            ## Start: Only for printing results\n",
    "            seg_list=list(reach['segments_list'])\n",
    "            seg_list=seg_list[::-1] #to reversed order\n",
    "            ncomp= len(reach['segments_list'])\n",
    "            for seg in range(0,ncomp):  \n",
    "                segID= seg_list[seg]\n",
    "                for ts in range (0,nts):\n",
    "                    print(f\"ts {ts} head_segment {head_segment} segINDEX {seg} segID {segID} \\\n",
    "                            FNL:ql qdc vel depth {flowdepthvel[segID]['qlat'][ts]} {flowdepthvel[segID]['flow'][ts]} \\\n",
    "                            {flowdepthvel[segID]['vel'][ts]} {flowdepthvel[segID]['depth'][ts]}\")  \n",
    "            ## End\n",
    "            with open(r\"./output/flowdepthvel.txt\",\"a\") as mc_result:\n",
    "                for seg in range(0,ncomp):  \n",
    "                    segID= seg_list[seg]\n",
    "                    for ts in range (0,nts):\n",
    "                        mc_result.write(\"%s %s %s %s %s %s\\n\" % (ts, segID, flowdepthvel[segID]['qlat'][ts], \n",
    "                            flowdepthvel[segID]['flow'][ts], flowdepthvel[segID]['vel'][ts], flowdepthvel[segID]['depth'][ts]))        \n",
    "    \n",
    "                          \n",
    "def main():\n",
    "\n",
    "    global connections\n",
    "    global networks\n",
    "    global flowdepthvel\n",
    "\n",
    "    verbose = True\n",
    "    debuglevel = 0\n",
    "    showtiming = True\n",
    "\n",
    "    test_folder = os.path.join(root, r'test')\n",
    "    geo_input_folder = os.path.join(test_folder, r'input', r'geo', r'Channels')\n",
    "\n",
    "    #TODO: Make these commandline args\n",
    "#     supernetwork= 'Pocono_TEST1'\n",
    "    supernetwork= 'Pocono_TEST2'\n",
    "    \"\"\"##NHD Subset (Brazos/Lower Colorado)\"\"\"\n",
    "#     supernetwork = 'Brazos_LowerColorado_ge5'\n",
    "    \"\"\"##NHD CONUS order 5 and greater\"\"\"\n",
    "    # supernetwork = 'CONUS_ge5'\n",
    "    \"\"\"These are large -- be careful\"\"\"\n",
    "#     supernetwork = 'Mainstems_CONUS'\n",
    "    # supernetwork = 'CONUS_FULL_RES_v20'\n",
    "    # supernetwork = 'CONUS_Named_Streams' #create a subset of the full resolution by reading the GNIS field\n",
    "    # supernetwork = 'CONUS_Named_combined' #process the Named streams through the Full-Res paths to join the many hanging reaches\n",
    "\n",
    "    if verbose: print('creating supernetwork connections set')\n",
    "    if showtiming: start_time = time.time()\n",
    "    #STEP 1\n",
    "    supernetwork_data, supernetwork_values = nnu.set_networks(\n",
    "        supernetwork = supernetwork\n",
    "        , geo_input_folder = geo_input_folder\n",
    "        , verbose = False\n",
    "        # , verbose = verbose\n",
    "        , debuglevel = debuglevel\n",
    "        )\n",
    "    if verbose: print('supernetwork connections set complete')\n",
    "    if showtiming: print(\"... in %s seconds.\" % (time.time() - start_time))\n",
    "\n",
    "    #STEP 2\n",
    "    if showtiming: start_time = time.time()\n",
    "    if verbose: print('organizing connections into networks and reaches ...')\n",
    "    networks = nru.compose_reaches(\n",
    "        supernetwork_values\n",
    "        , verbose = False\n",
    "        # , verbose = verbose\n",
    "        , debuglevel = debuglevel\n",
    "        , showtiming = showtiming\n",
    "        )\n",
    "    if verbose: print('reach organization complete')\n",
    "    if showtiming: print(\"... in %s seconds.\" % (time.time() - start_time))\n",
    "    \n",
    "\n",
    "    #STEP 3: Route NHD streamflow\n",
    "    if showtiming: start_time = time.time()\n",
    "    executiontype = 'serial' # 'parallel'\n",
    "\n",
    "    if verbose: print('executing serial computation on ordered reaches ...')\n",
    "    connections = supernetwork_values[0]\n",
    "\n",
    "    nts = 144  # number fof timestep = 1140 * 60(model timestep) = 86400 = day\n",
    "    dt_mc= 300.0 # time interval for MC\n",
    "    \n",
    "    # Lateral flow\n",
    "    ## test 1. Take lateral flow from wrf-hydro output from Pocono Basin\n",
    "    qlcol=54\n",
    "    qlrow=145\n",
    "    ql=np.zeros((qlrow,qlcol))\n",
    "    for j in range(0, qlcol):\n",
    "        ql[0,j]=np.loadtxt(\"./input/Pocono_ql_testsamp1_nwm_mc.txt\", max_rows=1,usecols=(j+2)) \n",
    "        ql[1:,j]=np.loadtxt(\"./input/Pocono_ql_testsamp1_nwm_mc.txt\", skiprows=1, usecols=(j+2))\n",
    "    latflow={}\n",
    "    for j in range(0,qlcol):\n",
    "        latflow.update({ql[0,j]:{'lateralflow':ql[1:,j]}})\n",
    "       \n",
    "    flowdepthvel = {connection:{'flow':np.zeros(nts)\n",
    "                                , 'depth':np.zeros(nts)\n",
    "                                , 'vel':np.zeros(nts)\n",
    "                                , 'qlat':np.zeros(nts)}\n",
    "                               for connection in connections}  \n",
    "\n",
    "    if executiontype == 'serial':\n",
    "        iter=0\n",
    "        for terminal_segment, network in networks.items():\n",
    "            if showtiming: network_start_time = time.time()\n",
    "#             iter=iter+1\n",
    "#             print(f\"terminal_segment iter-> {iter}\")\n",
    "\n",
    "            ## run MC to route network \n",
    "            mc_route_network(\n",
    "                  terminal_segment = terminal_segment\n",
    "                , network = network\n",
    "                , supernetwork_data = supernetwork_data\n",
    "                , nts = nts\n",
    "                , dt_mc= dt_mc\n",
    "                , latflow= latflow                \n",
    "#         , connections = None\n",
    "                , verbose = False\n",
    "                , debuglevel = 0\n",
    "            )\n",
    "        \n",
    "#             if verbose: print(f'{terminal_segment} completed')\n",
    "#             if showtiming: print(\"... in %s seconds.\" % (time.time() - network_start_time))\n",
    "        \n",
    "#     if verbose: print('ordered reach computation complete')\n",
    "#     if showtiming: print(\"... in %s seconds.\" % (time.time() - start_time))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
