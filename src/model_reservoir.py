
import numpy as np

import yaml
from array import array

from troute.network.reservoirs.levelpool.levelpool import MC_Levelpool
from troute.routing.fast_reach.reservoir_hybrid_da import reservoir_hybrid_da
from troute.routing.fast_reach.reservoir_RFC_da import reservoir_RFC_da, preprocess_RFC_data

class reservoir_model():

    def __init__(self, bmi_cfg_file=None):
        """
        
        """
        __slots__ = ['_levelpool','_inflow','_outflow','_water_elevation', '_res_type',
                     '_update_time', '_prev_persisted_flow', '_persistence_update_time',
                     '_persistence_index', '_time', '_time_step','_dynamic_res_type',
                     '_assimilated_value', '_assimilated_source_file',
                     '_levelpool_outflow,', '_timeseries_update_time',
                     '_timeseries_idx', '_rfc_gage_id', '_rfc_timeseries_folder',
                     '_rfc_timeseries_file', '_rfc_timeseries_offset_hours', '_rfc_forecast_persist_days',
                     '_time_step_seconds', '_total_counts', '_timeseries_discharges', 
                     '_use_RFC']
        
        if bmi_cfg_file:
            (bmi_parameters, #TODO We might not need any bmi specific parameters
             log_parameters, #TODO Update all logging/warnings throughout standalone reservoirs...
             compute_parameters,
             rfc_parameters) = _read_config_file(bmi_cfg_file)
            
            if compute_parameters:
                self._time_step = compute_parameters.get("model_time_step", 300)
                self._t0 = compute_parameters.get("model_start_time", None)
                if not self._t0:
                    raise(RuntimeError("No start_datetime provided in config file."))
            if rfc_parameters:
                self._rfc_gage_id = rfc_parameters.get("reservoir_rfc_gage_id", None)
                self._rfc_timeseries_folder = rfc_parameters.get("reservoir_rfc_timeseries_folder", None)
                self._rfc_timeseries_offset_hours = rfc_parameters.get("reservoir_rfc_timeseries_offset_hours", None)
                self._rfc_forecast_persist_days = rfc_parameters.get("reservoir_rfc_forecast_persist_days", 11)
            
        else:
            raise(RuntimeError("No config file provided."))
            
        self._time = 0.0
    

    def preprocess_static_vars(self, values: dict):

        lake_number = values['waterbody_id']
        lake_area = values['LkArea']
        max_depth = values['LkMxE']
        orifice_area = values['OrificeA']
        orifice_coefficient = values['OrificeC']
        orifice_elevation = values['OrificeE']
        weir_coefficient = values['WeirC']
        weir_elevation = values['WeirE']
        weir_length = values['WeirL']
        initial_fractional_depth = values['ifd']
        water_elevation = values['lake_surface__elevation']
        
        args = [lake_area, max_depth, orifice_area,
                orifice_coefficient, orifice_elevation,
                weir_coefficient, weir_elevation, weir_length,
                initial_fractional_depth, 0.0, water_elevation]
        
        upstream_ids = array('l', values['upstream_ids'])
        self._res_type = values['reservoir_type']

        self._levelpool = MC_Levelpool(0, lake_number, upstream_ids, args, 1)
        
        # Set inflow
        self._inflow = values['lake_water~incoming__volume_flow_rate']
        self._inflow_list = self._inflow.tolist()
        self._outflow_list = []
        self._water_elevation_list = []

        # Set data assimilation parameters
        if self._res_type==2 or self._res_type==3:
            self._update_time = 0
            self._prev_persisted_outflow = np.nan
            self._persistence_index = 0
            self._persistence_update_time = 0
        
        if self._res_type==4 or self._res_type==5:
            (self._use_RFC, 
             self._timeseries_discharges, 
             self._timeseries_idx, 
             self._update_time, 
             self._da_time_step, 
             self._total_counts,
             self._rfc_timeseries_file) = preprocess_RFC_data(self._t0,
                                     self._rfc_timeseries_offset_hours,
                                     self._rfc_gage_id,
                                     self._rfc_timeseries_folder,
                                     lake_number,
                                     self._time_step)

    def run(self, values: dict,):
        """
        Run this model into the future, updating the state stored in the provided model dict appropriately.
    
        Parameters
        ----------
        values: dict
            The model state data structure.
            
        Returns
        -------
        """
        # Check if new inflow values have been provided
        #TODO Should we come up with more clever way to do cycle through inflows for multiple time steps?
        if len(self._inflow_list)==0:
            self._inflow_list = self._inflow.tolist()

        # Get water elevation before levelpool calculation
        initial_water_elevation = self._levelpool.water_elevation

        # Run routing
        inflow = self._inflow_list.pop(0)
        self._levelpool_outflow, levelpool_water_elevation = self._levelpool.run(inflow, 0.0, self._time_step)

        # Data Assimilation
        if self._res_type==2 or self._res_type==3:
            (
                new_outflow,
                new_persisted_outflow,
                new_water_elevation, 
                new_update_time, 
                new_persistence_index, 
                new_persistence_update_time
            ) = reservoir_hybrid_da(
                self._levelpool.lake_number,        # lake identification number
                values['gage_observations'],        # gage observation values (cms)
                values['gage_time'],                # gage observation times (sec)
                self._time,                         # model time (sec)
                self._prev_persisted_outflow,       # previously persisted outflow (cms)
                self._persistence_update_time,      
                self._persistence_index,            # number of sequentially persisted update cycles
                self._levelpool_outflow,            # levelpool simulated outflow (cms)
                inflow,                             # waterbody inflow (cms)
                self._time_step,                    # model timestep = time step of inflow to reservoir (sec)
                self._levelpool.lake_area,          # waterbody surface area (km2)
                self._levelpool.max_depth,          # max waterbody depth (m)
                self._levelpool.orifice_elevation,  # orifice elevation (m)
                initial_water_elevation,            # water surface el., previous timestep (m)
                24.0,                               # gage lookback hours (hrs)
                self._update_time,                  # waterbody update time (sec)
            )
            
            # update levelpool water elevation state
            water_elevation = self._levelpool.assimilate_elevation(new_water_elevation)
            
            # change reservoir_outflow
            self._outflow = new_outflow
            
            # update USGS DA reservoir state arrays
            self._update_time = new_update_time
            self._prev_persisted_outflow = new_persisted_outflow
            self._persistence_index = new_persistence_index
            self._persistence_update_time = new_persistence_update_time
        
        elif self._res_type==4 or self._res_type==5:
            
            (
                new_outflow, 
                new_water_elevation, 
                new_update_time,
                new_timeseries_idx,
                dynamic_reservoir_type, 
                assimilated_value, 
                assimilated_source_file,
            ) = reservoir_RFC_da(
                self._use_RFC,                            # boolean whether to use RFC values or not
                self._timeseries_discharges,              # gage observation values (cms)
                self._timeseries_idx,                     # index of for current time series observation
                self._total_counts,                       # total number of observations in RFC timeseries
                self._time_step,                          # routing period (sec)
                self._time,                               # model time (sec)
                self._update_time,                        # time to advance to next time series index
                self._da_time_step,                       # frequency of DA observations (sec)
                self._rfc_forecast_persist_days*24*60*60, # max seconds RFC forecasts will be used/persisted (days -> seconds)
                self._res_type,                           # reservoir type
                inflow,                                   # waterbody inflow (cms)
                initial_water_elevation,                  # water surface el., previous timestep (m)
                self._levelpool_outflow,                  # levelpool simulated outflow (cms)
                levelpool_water_elevation,                # levelpool simulated water elevation (m)
                self._levelpool.lake_area*1.0e6,          # waterbody surface area (km2 -> m2)
                self._levelpool.max_depth,                # max waterbody depth (m)
                self._rfc_timeseries_file,                # RFC file name
            )

            # update levelpool water elevation state
            water_elevation = self._levelpool.assimilate_elevation(new_water_elevation)
            
            # change reservoir_outflow
            self._outflow = new_outflow

            # update DA reservoir state parameters
            self._update_time = new_update_time
            self._timeseries_idx = new_timeseries_idx
            self._dynamic_res_type = dynamic_reservoir_type
            self._assimilated_value = assimilated_value
            self._assimilated_source_file = assimilated_source_file

        # Set output variables
        values['lake_water~outgoing__volume_flow_rate'] = self._outflow
        values['lake_surface__elevation'] = water_elevation

        # Append outflow list
        self._outflow_list.append(self._outflow)
        self._water_elevation_list.append(water_elevation)

        # update model time
        self._time += self._time_step


# Utility functions -------
def _read_config_file(custom_input_file):
    '''
    Read-in data from user-created configuration file.
    
    Arguments
    ---------
    custom_input_file (str): configuration filepath, .yaml
    
    Returns
    -------
    bmi_parameters               (dict): Input parameters re bmi configuration
    log_parameters               (dict): Input parameters re logging
    compute_parameters           (dict): Input parameters re computation settings
    data_assimilation_parameters (dict): Input parameters re data assimilation

    '''
    with open(custom_input_file) as custom_file:
        data = yaml.load(custom_file, Loader=yaml.SafeLoader)

    bmi_parameters = data.get("bmi_parameters", None)
    log_parameters = data.get("log_parameters", None)
    compute_parameters = data.get("compute_parameters", None)
    data_assimilation_parameters = data.get("reservoir_data_assimilation_parameters", None)
    rfc_parameters = data_assimilation_parameters.get("rfc", None)

    return (
        bmi_parameters,
        log_parameters,
        compute_parameters,
        rfc_parameters,
    )