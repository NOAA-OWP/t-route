{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import sys\n",
    "import os\n",
    "from functools import partial\n",
    "import pandas as pd\n",
    "import geopandas\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "from collections import defaultdict, Counter, deque\n",
    "from itertools import chain\n",
    "\n",
    "# turn off warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "# append the system path with `/python_framework` directory\n",
    "# this is where some useful network analysis functions are stored\n",
    "sys.path.append(r\"../src/python_framework_v02\")\n",
    "\n",
    "# import t-route functions for network analysis\n",
    "import nhd_io\n",
    "import nhd_network\n",
    "import nhd_network_utilities_v02 as nnu\n",
    "\n",
    "# logic to accomodate Google Colab\n",
    "try:\n",
    "    import google.colab\n",
    "\n",
    "    ENV_IS_CL = True\n",
    "    root = r\"/content/t-route\"\n",
    "    subprocess.run([\"git\", \"clone\", \"https://github.com/NOAA-OWP/t-route.git\"])\n",
    "except:\n",
    "    root = os.path.dirname(os.path.abspath(\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decomposing supernetworks into networks and reaches\n",
    "- A key contribution of the t-route repository is the efficient decomposition of the national river network into subnetworks and interconnected reaches. This is important because:\n",
    "\n",
    "    1. Routing model application occurs at the reach scale. \n",
    "    \n",
    "    2. Mass a momentum balance requires mapping connections between reaches because water from upstream reaches flows into downstream reaches. \n",
    "    \n",
    "    3. Parallel routing computations across independent reaches or subnetworks can greatly reduce computational time. \n",
    "\n",
    "- A few definitions are necessary here:\n",
    "    - **Segment** - the elementary building blocks of a stream network defined as a linear strech of river with a certain length and uniform geomorphic parameters (e.g. width, slope, roughness, etc). Segments are the nodes in generic network lingo. \n",
    "    \n",
    "    - **Reach** - A linear combination of segments between two junction points, between a headwater and a junction, or between a junction and a tailwater. \n",
    "    \n",
    "    - **Subnetwork** - A series of connected segments (and reaches) that drain to the same tailwater.\n",
    "    \n",
    "    - **Supernetwork** - A large assembly of stream segments, often composing many different subnetworks.\n",
    "    \n",
    "- In practice we start with a *supernetwork* of connected and disconnected stream segments. For example, the NHDPlus dataset is a *supernetwork* that represents all of the mapped streams and rivers in the United States. \n",
    "\n",
    "- How then do we go about subdividing the *supernetwork* into constituent *subnetworks* and *reaches*?\n",
    "\n",
    "- The t-route repository contains a library of network analysis functions that solve this problem.\n",
    "\n",
    "- This notebook illustrates how network analysis functions are used to decompose the main stem CONUS stream network into constituent subnetworks and reaches. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identify the supernetwork data\n",
    "- First, we need to identify the supernetwork data\n",
    "- A function called `set_supernetwork_data` returns key metadata for the supernetwork. \n",
    "- In the cell below, you can experiment with different supernetwork options by commenting/uncommenting definitions for the variable, `supernetwork`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join /test/input/geo directory to the path - this is where geospatial test data are stored\n",
    "geo_input_folder = os.path.join(r\"../test/input/geo\")\n",
    "\n",
    "# Specify the supernetwork, for this example we will work with Mainstem_CONUS\n",
    "supernetwork = \"Mainstems_CONUS\"\n",
    "\n",
    "# get supernetwork information\n",
    "network_data = nnu.set_supernetwork_data(\n",
    "    supernetwork=supernetwork, geo_input_folder=geo_input_folder\n",
    ")\n",
    "\n",
    "# network data is a dictionary containing many useful metadata attributes for the supernetwork\n",
    "print(network_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and mask supernetwork data\n",
    "- Now that we have identified the supernetwork ,we can load it and apply the appropriate mask. \n",
    "- Masks are used here for development purposes. It is helpful to reduce the size of supernetwork dataset before we go about analyzing it. \n",
    "- `data` is a DataFrame with as many rows as there are segments in the supernetwork. Columns in the DataFrame contain segment-specific Muskingum-Cunge parameters. \n",
    "- `dat_geo` is also a DataFrame with as many rows as there are segments in the supernetwork, but all data columns are retained. We are going to convert this DataFrame to a GeoDataFrame for visualization purposes.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read-in the network data as a pandas.GeoDataFrame using functions in `nhd_io.py`\n",
    "data = nhd_io.read(network_data[\"geo_file_path\"])\n",
    "\n",
    "# grab column names from the network_data dictionary, by selecting keys that end with \"_col\"\n",
    "# These will be used to select specific data columns from the GeoDataFrame\n",
    "cols = [v for c, v in network_data.items() if c.endswith(\"_col\")]\n",
    "\n",
    "# retain a copy of the data set to be translated into a GeoDataFrame\n",
    "dat_geo = data.copy()\n",
    "\n",
    "# select only the columns we need from the GeoDataFrame, creating a new and smaller DataFrame\n",
    "data = data[cols]\n",
    "\n",
    "# set the Data Frame index (row labels) to the key column - \"featureID\"\n",
    "data = data.set_index(network_data[\"key_col\"])\n",
    "dat_geo = dat_geo.set_index(network_data[\"key_col\"])\n",
    "\n",
    "# sort the DataFrame by featureID, ascending order.\n",
    "data = data.sort_index()\n",
    "\n",
    "# apply a mask to extract only a subset of the greater CONUS stream network\n",
    "if \"mask_file_path\" in network_data:\n",
    "    data_mask = nhd_io.read_mask(\n",
    "        network_data[\"mask_file_path\"], layer_string=network_data[\"mask_layer_string\"],\n",
    "    )\n",
    "    data = data.filter(data_mask.iloc[:, network_data[\"mask_key\"]], axis=0)\n",
    "    dat_geo = dat_geo.filter(data_mask.iloc[:, network_data[\"mask_key\"]], axis=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the supernetwork\n",
    "- To visualize the supernetwork, we need to convert the `dat_geo` DataFrame to a GeoDataFrame, named `gdf`.\n",
    "- The GeoDataFrame contains geometry information that can be easily plotted.\n",
    "- We make a simple map that represents all segments in the supernetwork as small points on a CONUS basemap. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a GeoDataFrame for viz purposes\n",
    "gdf = geopandas.GeoDataFrame(\n",
    "    dat_geo, geometry=geopandas.points_from_xy(dat_geo.lon, dat_geo.lat)\n",
    ")\n",
    "\n",
    "# import world basemap\n",
    "world = geopandas.read_file(geopandas.datasets.get_path(\"naturalearth_lowres\"))\n",
    "\n",
    "# create a basemap showing the boundaries of the USA\n",
    "base = world[world.name == \"United States of America\"].plot(\n",
    "    color=\"white\", edgecolor=\"black\"\n",
    ")\n",
    "\n",
    "# add our stream network, segments are represented as small points (nodes in the network)\n",
    "gdf.plot(ax=base, markersize=0.01, color=\"black\")\n",
    "\n",
    "# crop the map extent\n",
    "base.set_xlim(-130, -60)\n",
    "base.set_ylim(20, 52)\n",
    "\n",
    "base.axis(\"off\")\n",
    "\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(18.5, 10.5)\n",
    "\n",
    "# add a title and display\n",
    "plt.title(\"The CONUS (mainstem) supernetwork\", fontsize=20)\n",
    "\n",
    "plt.show()\n",
    "fig.savefig(\"../doc/conus_supernetwork.png\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handle terminal segments\n",
    "- In the native data, terminal segments (those that do not flow into another segment) have a downstream segment ID of zero in the downstream column of the DataFrame. This is problematic because all tailwaters point to a common drainage node, making it appear that all stream segments are part of the same network, which they are not. Therefore, it is necessary to create a new naming convention for the downstream connections of terminal segments. \n",
    "- The function `repace_downstreams` changes zeros to the negative of the terminal segment ID. For example, segment ID 12345 is a terminal segment, the downstream segment ID will be set to -12345. After applying this function, all tailwaters will now have a unique downstream connection. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = nhd_io.replace_downstreams(data, network_data[\"downstream_col\"], 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract network connections\n",
    "- Downstream and upstream network connections are extracted with the `extract_network` and `reverse_network` functions, respectively.\n",
    "- `extract_network` accepts the network DataFrame, `data`, and returns a dictionary of segments and their respective downstream connections. \n",
    "- `reverse_network` flips the edge orientation of the network such headwaters in the original become tailwaters in the reversed network. In doing so, each segment's upstream connections are identified. The function accepts the `connections` dictionary, and returns a dictionary of segments and their respective upstream connections. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given the network DataFrame, `extract_network` returns a dictionary segments and downstream connections.\n",
    "# segment-id: [downstream-connected-segment-id]\n",
    "connections = nhd_network.extract_connections(data, network_data[\"downstream_col\"])\n",
    "\n",
    "# flip the orientation of the network from headwaters -> tailwaters, to tailwaters -> headwaters\n",
    "# this allows us to enumerate each segment's upstream neighbor\n",
    "# segment-id: [upstream-connected-segment-id]\n",
    "rconn = nhd_network.reverse_network(connections)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check that the supernetwork network is a Directed Acyclic Graph\n",
    "- A [Directed Acyclic Graph (DAG)](https://en.wikipedia.org/wiki/Directed_acyclic_graph) is a network consisting of many nodes and edges, each edge is *directed* from one node to another, and it is impossible to traverse the network in a way that the starting and ending nodes are the same (i.e. *acyclic*). \n",
    "- Because of gravity, river networks must be DAGs. Water must flow down energy gradients oriented in the direction of gravitational forces. As a result flows cannot \"loop back\" to an origination point. \n",
    "- To check that the supernetwork is a DAG, we use [Kahn's Algorithm](https://en.wikipedia.org/wiki/Topological_sorting#Kahn's_algorithm) for topological sorting.\n",
    "- Subsequent network analyses assume *a priori* that the network is a DAG, so checking is critical. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identify subnetworks\n",
    "- The `reachable` function breaks the supernetwork into constituent subnetworks by extracting all segments connected to each tailwater segment. \n",
    "- The function accepts a network (in this case the reversed network, rconn) and returns a dictionary where the keys are tailwater nodes and the values are the sets of nodes reachable from each tailwater node.\n",
    "- Example output is shown for a single tailwater segment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# determine all of the stream segments with upstream connections to each tail water (terminal node) in the supernetwork\n",
    "# note we hand the `reachable` function the reversed network dictionary `rconn`\n",
    "# tailwater-segment-id: [list of ALL upstream connected segment ids]\n",
    "subreachable = nhd_network.reachable(rconn)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize subnetworks\n",
    "- Make a map showing each of the subnetworks in the supernetwork with different colors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Get the tailwater keys for each subnetwork\n",
    "n_subnets = subreachable.keys()\n",
    "\n",
    "# # initialize a new column in the GeoDataFrame that will contain subnetwork code\n",
    "gdf[\"subnetwork\"] = 0\n",
    "\n",
    "for i, reached in enumerate(subreachable.values(), 1):\n",
    "\n",
    "    gdf.loc[gdf.index.isin(reached), \"subnetwork\"] = i\n",
    "\n",
    "# CONUS basemap\n",
    "base = world[world.name == \"United States of America\"].plot(\n",
    "    color=\"white\", edgecolor=\"black\"\n",
    ")\n",
    "\n",
    "# add our stream network, using different marker colors for each subnetwork\n",
    "gdf.plot(ax=base, markersize=0.01, column=\"subnetwork\", cmap=\"prism\")\n",
    "\n",
    "# crop the map extent\n",
    "base.set_xlim(-130, -60)\n",
    "base.set_ylim(20, 52)\n",
    "\n",
    "base.axis(\"off\")\n",
    "\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(18.5, 10.5)\n",
    "\n",
    "\n",
    "plt.title(\"The supernetwork broken into subnetworks\", fontsize=20)\n",
    "plt.show()\n",
    "fig.savefig(\"../doc/conus_networks.png\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identify reaches\n",
    "- Identifying reaches in each subnetwork is a two step process\n",
    "    1. Use the `reachable_network` function to identify the upstream connectivity structure of each subnetwork. The function accepts the reverse network dictionary, `rconn`, and returns a dictionary, `subnets_`, which lists upstream connections for each segment in each subnetwork. \n",
    "    2. Conduct a [depth-first-search](https://en.wikipedia.org/wiki/Depth-first_search) of each subnetwork. This is done with the `dfs_decomposition` function, which accepts the forward (downstream oriented) network dictionary, and returns a dictionary of upstream-to-downstream ordered linear segment combinations that comprise each reach in the network. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create reverse connection dictionary for each subnetwork\n",
    "# tailwater-segment-id: {segment-id: [upstream-connected-segment-id]}\n",
    "subnets_ = nhd_network.reachable_network(rconn)\n",
    "\n",
    "# create a dictionary, `subreaches` containing lists of all linear connected segments between junctions (reaches) in the supernetwork.\n",
    "# Recall, a reach is composed of several interconnected segments between junctions.\n",
    "# tailwater-segment-id: [[rch1-segment-id-1, rch1-segment-id-2, ..., rch1-segment-id-n],[rch2-segment-id1, rch2-segment-id2, ..., rch2-segment-id-n]]\n",
    "subreaches = {}\n",
    "for tw, net in subnets_.items():  # for the number of tailwaters in the supernetwork\n",
    "\n",
    "    # I dont know what this does... something with identifying junctions\n",
    "    path_func = partial(nhd_network.split_at_junction, net)\n",
    "\n",
    "    # conduct a depth-first search to decompose the network into list of reaches\n",
    "    reach = nhd_network.dfs_decomposition(net, path_func)\n",
    "\n",
    "    # add reach list for subnetwork tw to the subreaches library\n",
    "    subreaches[tw] = reach\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize reaches in a single subnetwork\n",
    "- Make a map showing each of the reaches in the Colorado River Basin subnetwork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract a single large subnetwork from the supernetwork GeoDataFrame.\n",
    "# Turns out that subnetwork code 4 is the Colorado River Basin\n",
    "# !!! TODO: Create some sort of look up table to query river basins by name, rather than some arbitrary number\n",
    "sub_gdf = gdf[gdf[\"subnetwork\"] == 4]\n",
    "\n",
    "# get reaches in the subnetwork\n",
    "rchs = subreaches[list(sub_gdf[[\"to\"]].idxmin())[0]]\n",
    "\n",
    "# create a reach-code column in the GeoDataFrame\n",
    "sub_gdf[\"reach\"] = 0\n",
    "\n",
    "# loop through all reaches in the subnetwork, populate the newly created \"reach\" column with an integer reach identification code\n",
    "i = 1\n",
    "for r in rchs:\n",
    "\n",
    "    # get the stream segments in subnetwork `sub`\n",
    "    A = list(map(abs, r))\n",
    "\n",
    "    # find the subnetwork rows in GeoDataFrame\n",
    "    C = sub_gdf.index.isin(A)\n",
    "\n",
    "    # Insert a subnetwork code in the `subnetwork` column of the GeoDataFrame\n",
    "    sub_gdf.at[C, \"reach\"] = i\n",
    "\n",
    "    # advance itteration index\n",
    "    i = i + 1\n",
    "\n",
    "\n",
    "# CONUS basemap\n",
    "base = world[world.name == \"United States of America\"].plot(\n",
    "    color=\"white\", edgecolor=\"black\"\n",
    ")\n",
    "\n",
    "sub_gdf.plot(ax=base, markersize=0.1, column=\"reach\", cmap=\"prism\")\n",
    "\n",
    "# crop map extent\n",
    "base.set_xlim(-130, -100)\n",
    "base.set_ylim(20, 45)\n",
    "\n",
    "base.axis(\"off\")\n",
    "\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(18.5, 10.5)\n",
    "\n",
    "plt.title(\"The Colorado River Basin subnetwork broken into reaches\", fontsize=20)\n",
    "plt.show()\n",
    "fig.savefig(\"../doc/colorado_reaches.png\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recap\n",
    "- This notebook illustrates how the t-route library analyzes network information to decompose supernetworks into constituent subnetworks and reaches. This is a critical component of the flood routing process that quantifies the complex connectivity of continental-scale river networks. \n",
    "- Key functions used in the t-route library include\n",
    "    - `nhd_network_utilities_v02.set_supernetwork_data`\n",
    "    - `nhd_io.read`\n",
    "    - `nhd_io.replace_downstreams`\n",
    "    - `nhd_network.extract_network`\n",
    "    - `nhd_network.reverse_network`\n",
    "    - `nhd_network.reachable`\n",
    "    - `nhd_network.reachable_network`\n",
    "    - `nhd_network.dfs_decomposition`  \n",
    "    \n",
    "- The utility of these functions is illustrated by an example where the CONUS (mainstem) supernetwork is broken into subnetworks, and then further broken into reaches. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
